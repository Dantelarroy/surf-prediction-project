name: Daily Surf Data Scraper

on:
  schedule:
    - cron: "21 21 * * *"  # Ejecutar todos los días a las 18:00 (Hora Argentina UTC-3)
  workflow_dispatch: # Permitir ejecución manual desde la interfaz de GitHub
  
jobs:
  run-scraper:
    runs-on: windows-latest  # Usar Windows como sistema base

    steps:
      # Paso 1: Checkout del repositorio
      - name: Checkout repository
        uses: actions/checkout@v4

      # Paso 2: Configurar Python 3.10
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      # Paso 3: Instalar Poetry usando curl
      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -

      # Paso 4: Establecer las variables de entorno para Poetry
      - name: Set Poetry environment variables
        run: |
          echo "POETRY_CONFIG_DIR=${GITHUB_WORKSPACE}/.poetry/config" >> $GITHUB_ENV
          echo "POETRY_HOME=${GITHUB_WORKSPACE}/.poetry" >> $GITHUB_ENV

      # Paso 5: Verificar que Poetry está disponible
      - name: Verify Poetry Installation
        run: |
          poetry --version  # Debería devolver la versión instalada de Poetry

      # Paso 6: Instalar dependencias con Poetry
      - name: Install dependencies
        run: |
          poetry install --no-root

      # Paso 7: Instalar Jupyter
      - name: Install Jupyter
        run: |
          poetry run pip install notebook

      # Paso 8: Ejecutar los notebooks
      - name: Run Ingesta_pysurfline notebook
        run: |
          poetry run jupyter nbconvert --to notebook --execute main/Ingesta_pysurfline.ipynb --output main/Ingesta_pysurfline_output.ipynb

      - name: Run surfline_scrap notebook
        run: |
          poetry run jupyter nbconvert --to notebook --execute main/surfline_scrap.ipynb --output main/surfline_scrap_output.ipynb

      # Paso 9: Confirmar que los archivos xlsx han sido actualizados
      - name: Add and Commit updated xlsx files
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add data/pg_pysurfline.xlsx data/pg_scrap_surfline.xlsx
          git commit -m "Update XLSX files [CI]"
          git push origin main

      # Paso 10: Ejecutar el script de log para registrar el resultado
      - name: Log the result
        run: |
          poetry run python main/logs.py
