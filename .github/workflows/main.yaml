name: Daily Surf Data Scraper

on:
  schedule:
    - cron: "21 21 * * *"  # Ejecutar todos los días a las 18:00 (Hora Argentina UTC-3)
  workflow_dispatch: # Permitir ejecución manual desde la interfaz de GitHub
  
jobs:
  run-scraper:
    runs-on: windows-latest  # Usar Windows como sistema base

    steps:
      # Paso 1: Checkout del repositorio
      - name: Checkout repository
        uses: actions/checkout@v4

      # Paso 2: Configurar Python 3.10
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      # Paso 3: Instalar Poetry usando la acción setup-poetry
      - name: Setup Poetry
        uses: Gr1N/setup-poetry@v8  # Usando la acción oficial de setup-poetry
        with:
          version: "1.8.0"  # Especifica la versión de Poetry que deseas instalar
          cache-poetry: "true"  # Opcional: Habilitar caché de Poetry para acelerar el proceso
          cache-venv: "true"  # Opcional: Habilitar caché del entorno virtual para acelerar la ejecución

      # Paso 4: Verificar la instalación de Poetry
      - name: Verify Poetry Installation
        run: |
          poetry --version  # Esto debería devolver la versión instalada de Poetry

      # Paso 5: Instalar dependencias con Poetry
      - name: Install dependencies
        run: |
          poetry install --no-root

      # Paso 6: Instalar Jupyter
      - name: Install Jupyter
        run: |
          poetry run pip install notebook

      # Paso 7: Ejecutar los scripts Python directamente
      # - name: Run Ingesta_pysurfline script
      #   run: |
      #     poetry run python main/Ingesta_pysurfline.py

      - name: Run surfline_scrap script
        run: |
          poetry run python main/surfline_scrap.py

      # Paso 8: Confirmar que los archivos xlsx han sido actualizados
      - name: Add and Commit updated xlsx files
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add data/pg_pysurfline.xlsx data/pg_scrap_surfline.xlsx
          git commit -m "Update XLSX files [CI]"
          git push origin main

      # Paso 9: Ejecutar el script de log para registrar el resultado
      - name: Log the result
        run: |
          poetry run python main/logs.py